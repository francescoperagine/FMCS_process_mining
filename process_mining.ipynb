{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pm4py\n",
    "import os\n",
    "from pm4py.algo.discovery.alpha import algorithm as alpha_miner\n",
    "from pm4py.algo.discovery.heuristics import algorithm as heuristics_miner\n",
    "from pm4py.algo.discovery.inductive import algorithm as inductive_miner\n",
    "from pm4py.visualization.petri_net import visualizer as pn_visualizer\n",
    "from pm4py.algo.evaluation.replay_fitness import algorithm as replay_fitness_evaluator\n",
    "from pm4py.algo.evaluation.precision import algorithm as precision_evaluator\n",
    "from pm4py.algo.evaluation.generalization import algorithm as generalization_evaluator\n",
    "from pm4py.algo.evaluation.simplicity import algorithm as simplicity_evaluator\n",
    "from pm4py.objects.conversion.process_tree import converter as pt_converter\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily approach\n",
    "\n",
    "def prepare_dataset(file_path):\n",
    "    with open(file_path, \"r\") as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    df = pd.DataFrame([line.split() for line in lines], columns=[\"Date\", \"Time\", \"org:resource\", \"lifecycle:transition\", \"concept:name\"])\n",
    "\n",
    "    df[\"time:timestamp\"] = pd.to_datetime(df[\"Date\"] + \" \" + df[\"Time\"], format='ISO8601')\n",
    "    df['case:concept:name'] = df['time:timestamp'].dt.date.astype(str)\n",
    "\n",
    "    df = df.drop(columns=[\"Date\", \"Time\"])\n",
    "\n",
    "    return df[[\"case:concept:name\", \"time:timestamp\", \"concept:name\", \"org:resource\", \"lifecycle:transition\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Session approach\n",
    "\n",
    "# def prepare_dataset(file_path):\n",
    "#     with open(file_path, \"r\") as file:\n",
    "#         lines = file.readlines()\n",
    "\n",
    "#     df = pd.DataFrame([line.split() for line in lines],  columns=[\"Date\", \"Time\", \"org:resource\", \"lifecycle:transition\", \"concept:name\"])\n",
    "    \n",
    "#     # Convert to datetime and sort chronologically\n",
    "#     df[\"time:timestamp\"] = pd.to_datetime(df[\"Date\"] + \" \" + df[\"Time\"], format='ISO8601')\n",
    "#     df = df.sort_values('time:timestamp')\n",
    "    \n",
    "#     # Calculate time differences between consecutive events\n",
    "#     time_diff = df['time:timestamp'].diff()\n",
    "    \n",
    "#     # Start new session when:\n",
    "#     # 1. There's a gap of more than 4 hours between activities\n",
    "#     # 2. A Sleep activity starts\n",
    "#     new_session = (\n",
    "#         (time_diff > pd.Timedelta(hours=4)) | \n",
    "#         ((df['concept:name'] == 'Sleep') & (df['lifecycle:transition'] == 'ON'))\n",
    "#     )\n",
    "    \n",
    "#     # Create session IDs\n",
    "#     df['case:concept:name'] = new_session.cumsum().astype(str)\n",
    "\n",
    "#     # Keep required columns in correct order\n",
    "#     df = df[[\n",
    "#         'case:concept:name',\n",
    "#         'time:timestamp',\n",
    "#         'concept:name',\n",
    "#         'org:resource',\n",
    "#         'lifecycle:transition'\n",
    "#     ]]\n",
    "    \n",
    "#     # Drop unused columns and reorder\n",
    "#     df = df.drop(columns=[\"Date\", \"Time\"])\n",
    "    \n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_process_mining(log):\n",
    "\n",
    "    alpha_net, alpha_initial_marking, alpha_final_marking = alpha_miner.apply(log)\n",
    "    heuristic_net, heu_initial_marking, heu_final_marking = heuristics_miner.apply(log)\n",
    "    inductive_tree = inductive_miner.apply(log)\n",
    "    inductive_net, ind_initial_marking, ind_final_marking = pt_converter.apply(inductive_tree)\n",
    "\n",
    "    models = {\n",
    "        'Alpha': (alpha_net, alpha_initial_marking, alpha_final_marking),\n",
    "        'Heuristic': (heuristic_net, heu_initial_marking, heu_final_marking),\n",
    "        'Inductive': (inductive_net, ind_initial_marking, ind_final_marking)\n",
    "    }\n",
    "    \n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(log, models):\n",
    "    metrics = {}\n",
    "    \n",
    "    for name, (net, initial_marking, final_marking) in models.items():\n",
    "        fitness = replay_fitness_evaluator.apply(log, net, initial_marking, final_marking)\n",
    "        precision = precision_evaluator.apply(log, net, initial_marking, final_marking)\n",
    "        generalization = generalization_evaluator.apply(log, net, initial_marking, final_marking)\n",
    "        simplicity = simplicity_evaluator.apply(net)\n",
    "        \n",
    "        metrics[name] = {\n",
    "            'Fitness': fitness['average_trace_fitness'],\n",
    "            'Precision': precision,\n",
    "            'Generalization': generalization,\n",
    "            'Simplicity': simplicity\n",
    "        }\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics_comparison(metrics, figures_folder):\n",
    "    # Convert metrics to DataFrame\n",
    "    metrics_df = pd.DataFrame(metrics).T\n",
    "    \n",
    "    # Create figure and axis\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    # Plot bars\n",
    "    metrics_df.plot(kind='bar', width=0.8, ax=ax)\n",
    "    \n",
    "    # Add value labels on top of each bar\n",
    "    for container in ax.containers:\n",
    "        ax.bar_label(container, fmt='%.3f', padding=3)\n",
    "    \n",
    "    # Customize plot\n",
    "    plt.title('Process Mining Metrics Comparison')\n",
    "    plt.xlabel('Miners')\n",
    "    plt.ylabel('Score')\n",
    "    plt.legend(title='Metrics', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    # Adjust layout to prevent label cutoff\n",
    "    plt.subplots_adjust(right=0.85, bottom=0.15)\n",
    "    \n",
    "    # Save plot\n",
    "    output_path = os.path.join(figures_folder, f\"metrics_comparison.png\")\n",
    "    plt.savefig(output_path, bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    # Print numerical values in console\n",
    "    print(\"\\nNumerical Metrics:\")\n",
    "    print(metrics_df.round(3).to_string())\n",
    "    return metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_petri_nets(models, figures_folder):\n",
    "    os.makedirs(figures_folder, exist_ok=True)\n",
    "    for name, (net, initial_marking, final_marking) in models.items():\n",
    "        gviz = pn_visualizer.apply(net, initial_marking, final_marking)\n",
    "        output_path = os.path.join(figures_folder, f\"petri_net_{name.lower()}.png\")\n",
    "        pn_visualizer.save(gviz, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_user_habits(log, processed_folder):\n",
    "    # Extract activity patterns\n",
    "    activities_by_day = {}\n",
    "    for trace in log:\n",
    "        day = trace.attributes['concept:name']\n",
    "        activities = [(event['concept:name'], event['lifecycle:transition']) for event in sorted(trace, key=lambda x: x['time:timestamp'])]\n",
    "        activities_by_day[day] = activities\n",
    "    \n",
    "    # Analyze common patterns\n",
    "    common_sequences = {}\n",
    "    \n",
    "    for day, activities in activities_by_day.items():\n",
    "        current_activity = None\n",
    "        sequence_parts = []\n",
    "\n",
    "        for activity, state in activities:\n",
    "            # Only add new activities when they start (ON state)\n",
    "            if current_activity != activity and state == 'ON':\n",
    "                sequence_parts.append(activity)\n",
    "                current_activity = activity\n",
    "        \n",
    "        # Only create sequence if there are activities\n",
    "        if sequence_parts:\n",
    "            sequence = ' -> '.join(sequence_parts)\n",
    "            common_sequences[sequence] = common_sequences.get(sequence, 0) + 1\n",
    "\n",
    "    # Sort by frequency\n",
    "    sorted_sequences = dict(sorted(common_sequences.items(),  key=lambda x: x[1], reverse=True))\n",
    "\n",
    "    output_file = os.path.join(processed_folder, \"user_habits_analysis.txt\")\n",
    "\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        for sequence, count in sorted(sorted_sequences.items(), key=lambda x: x[1], reverse=True):\n",
    "            f.write(f'Frequency: {count}\\nSequence: {sequence}\\n\\n')\n",
    "    \n",
    "    return sorted_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "\n",
    "input_file = os.path.join('data', 'raw', 'tm001.txt')\n",
    "\n",
    "df = prepare_dataset(input_file)\n",
    "df_stratified = df.groupby('concept:name').apply(lambda x: x.sample(5)).reset_index(drop=True)\n",
    "\n",
    "# Convert to event log\n",
    "log = pm4py.convert_to_event_log(df_stratified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "figures_folder = os.path.join('resources', 'figures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply process mining\n",
    "models = apply_process_mining(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "metrics = calculate_metrics(log, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot comparisons\n",
    "plot_metrics_comparison(metrics, figures_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Petri nets\n",
    "visualize_petri_nets(models, figures_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze user habits\n",
    "user_habits_path = os.path.join('data', 'processed')\n",
    "habits = analyze_user_habits(log, user_habits_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
