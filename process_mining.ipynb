{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pm4py\n",
    "import os\n",
    "from pm4py.algo.discovery.alpha import algorithm as alpha_miner\n",
    "from pm4py.algo.discovery.heuristics import algorithm as heuristics_miner\n",
    "from pm4py.algo.discovery.inductive import algorithm as inductive_miner\n",
    "from pm4py.visualization.petri_net import visualizer as pn_visualizer\n",
    "from pm4py.algo.evaluation.replay_fitness import algorithm as replay_fitness_evaluator\n",
    "from pm4py.algo.evaluation.precision import algorithm as precision_evaluator\n",
    "from pm4py.algo.evaluation.generalization import algorithm as generalization_evaluator\n",
    "from pm4py.algo.evaluation.simplicity import algorithm as simplicity_evaluator\n",
    "from pm4py.objects.conversion.process_tree import converter as pt_converter\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(file_path, approach='daily', session_gap_hours=4):\n",
    "    \"\"\"\n",
    "    Prepare dataset using either daily or session-based approach.\n",
    "    \n",
    "    Parameters:\n",
    "    file_path (str): Path to the input file\n",
    "    approach (str): Either 'daily' or 'session'\n",
    "    session_gap_hours (int): Hours gap to define a new session (only for session approach)\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: Processed DataFrame with required columns\n",
    "    \"\"\"\n",
    "    with open(file_path, \"r\") as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    df = pd.DataFrame([line.split() for line in lines], \n",
    "                     columns=[\"Date\", \"Time\", \"org:resource\", \"lifecycle:transition\", \"concept:name\"])\n",
    "    \n",
    "    # Convert to datetime and sort chronologically\n",
    "    df[\"time:timestamp\"] = pd.to_datetime(df[\"Date\"] + \" \" + df[\"Time\"], format='ISO8601')\n",
    "    df = df.sort_values('time:timestamp')\n",
    "    \n",
    "    if approach == 'daily':\n",
    "        # Daily approach: use calendar date as case identifier\n",
    "        df['case:concept:name'] = df['time:timestamp'].dt.date.astype(str)\n",
    "    \n",
    "    elif approach == 'session':\n",
    "        # Session approach: identify sessions based on time gaps and sleep activity\n",
    "        time_diff = df['time:timestamp'].diff()\n",
    "        new_session = (\n",
    "            (time_diff > pd.Timedelta(hours=session_gap_hours)) | \n",
    "            ((df['concept:name'] == 'Sleep') & (df['lifecycle:transition'] == 'ON'))\n",
    "        )\n",
    "        df['case:concept:name'] = new_session.cumsum().astype(str)\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"approach must be either 'daily' or 'session'\")\n",
    "    \n",
    "    # Keep required columns in correct order and drop unused ones\n",
    "    df = df[[\n",
    "        'case:concept:name',\n",
    "        'time:timestamp',\n",
    "        'concept:name',\n",
    "        'org:resource',\n",
    "        'lifecycle:transition'\n",
    "    ]]\n",
    "    \n",
    "    # Count distinct values for each attribute\n",
    "    # distinct_counts = df.nunique()\n",
    "    # print(\"Attributes counts:\")\n",
    "    # display(distinct_counts.to_frame().T)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_process_mining(log):\n",
    "\n",
    "    alpha_net, alpha_initial_marking, alpha_final_marking = alpha_miner.apply(log)\n",
    "    heuristic_net, heu_initial_marking, heu_final_marking = heuristics_miner.apply(log)\n",
    "    inductive_tree = inductive_miner.apply(log)\n",
    "    inductive_net, ind_initial_marking, ind_final_marking = pt_converter.apply(inductive_tree)\n",
    "\n",
    "    models = {\n",
    "        'Alpha': (alpha_net, alpha_initial_marking, alpha_final_marking),\n",
    "        'Heuristic': (heuristic_net, heu_initial_marking, heu_final_marking),\n",
    "        'Inductive': (inductive_net, ind_initial_marking, ind_final_marking)\n",
    "    }\n",
    "    \n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(log, models):\n",
    "    metrics = {}\n",
    "    \n",
    "    for name, (net, initial_marking, final_marking) in models.items():\n",
    "        fitness = replay_fitness_evaluator.apply(log, net, initial_marking, final_marking)\n",
    "        precision = precision_evaluator.apply(log, net, initial_marking, final_marking)\n",
    "        generalization = generalization_evaluator.apply(log, net, initial_marking, final_marking)\n",
    "        simplicity = simplicity_evaluator.apply(net)\n",
    "        \n",
    "        metrics[name] = {\n",
    "            'Fitness': fitness['average_trace_fitness'],\n",
    "            'Precision': precision,\n",
    "            'Generalization': generalization,\n",
    "            'Simplicity': simplicity\n",
    "        }\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics_comparison(metrics, dataset_approach, figures_folder):\n",
    "    # Convert metrics to DataFrame\n",
    "    metrics_df = pd.DataFrame(metrics).T\n",
    "    \n",
    "    # Create figure and axis\n",
    "    _, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    # Plot bars\n",
    "    metrics_df.plot(kind='bar', width=0.8, ax=ax)\n",
    "    \n",
    "    # Add value labels on top of each bar\n",
    "    for container in ax.containers:\n",
    "        ax.bar_label(container, fmt='%.3f', padding=3)\n",
    "    \n",
    "    # Customize plot\n",
    "    plt.title(f'Metrics Comparison - {dataset_approach} approach')\n",
    "    plt.xlabel('Miners')\n",
    "    plt.ylabel('Score')\n",
    "    plt.legend(title='Metrics', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    # Adjust layout to prevent label cutoff\n",
    "    plt.subplots_adjust(right=0.85, bottom=0.15)\n",
    "    \n",
    "    # Save plot\n",
    "    output_path = os.path.join(figures_folder, f\"metrics_comparison_{dataset_approach}.png\")\n",
    "    plt.savefig(output_path, bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    # Print numerical values in console\n",
    "    # print(\"\\nNumerical Metrics:\")\n",
    "    # print(metrics_df.round(3).to_string())\n",
    "    return metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_petri_nets(models, dataset_approach, figures_folder):\n",
    "    os.makedirs(figures_folder, exist_ok=True)\n",
    "    for name, (net, initial_marking, final_marking) in models.items():\n",
    "        gviz = pn_visualizer.apply(net, initial_marking, final_marking)\n",
    "        output_path = os.path.join(figures_folder, f\"petri_net_{name.lower()}_{dataset_approach}.png\")\n",
    "        pn_visualizer.save(gviz, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_user_habits(log, dataset_approach, processed_folder):\n",
    "    # Extract activity patterns\n",
    "    activities_by_day = {}\n",
    "    for trace in log:\n",
    "        day = trace.attributes['concept:name']\n",
    "        activities = [(event['concept:name'], event['lifecycle:transition']) for event in sorted(trace, key=lambda x: x['time:timestamp'])]\n",
    "        activities_by_day[day] = activities\n",
    "    \n",
    "    # Analyze common patterns\n",
    "    common_sequences = {}\n",
    "    \n",
    "    for day, activities in activities_by_day.items():\n",
    "        current_activity = None\n",
    "        sequence_parts = []\n",
    "\n",
    "        for activity, state in activities:\n",
    "            # Only add new activities when they start (ON state)\n",
    "            if current_activity != activity and state == 'ON':\n",
    "                sequence_parts.append(activity)\n",
    "                current_activity = activity\n",
    "        \n",
    "        # Only create sequence if there are activities\n",
    "        if sequence_parts:\n",
    "            sequence = ' -> '.join(sequence_parts)\n",
    "            common_sequences[sequence] = common_sequences.get(sequence, 0) + 1\n",
    "\n",
    "    # Sort by frequency\n",
    "    sorted_sequences = dict(sorted(common_sequences.items(),  key=lambda x: x[1], reverse=True))\n",
    "\n",
    "    output_file = os.path.join(processed_folder, f\"user_habits_analysis_{dataset_approach}.txt\")\n",
    "\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        for sequence, count in sorted(sorted_sequences.items(), key=lambda x: x[1], reverse=True):\n",
    "            f.write(f'Frequency: {count}\\nSequence: {sequence}\\n\\n')\n",
    "    \n",
    "    return sorted_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "figures_folder = os.path.join('resources', 'figures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_11976\\2035488507.py:10: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_stratified = df.groupby('concept:name').apply(lambda x: x.sample(5)).reset_index(drop=True)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0462184a42484e02a8acf1db3173806b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "aligning log, completed variants ::   0%|          | 0/54 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "230d275be1be4d158d1faecc4939fabd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "computing precision with alignments, completed variants ::   0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e90085c67b14372ba3235b659760759",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "replaying log with TBR, completed traces ::   0%|          | 0/54 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1032c692978e4066a3a36e674ebed468",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "aligning log, completed variants ::   0%|          | 0/54 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9037062e885c445fb7d1219855af3d4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "computing precision with alignments, completed variants ::   0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da1ab097cf374339b3d8519ae309af2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "replaying log with TBR, completed traces ::   0%|          | 0/54 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "158a7eb71ab74ff98b6ec8a0cbfabf5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "aligning log, completed variants ::   0%|          | 0/54 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1991619aff543c6aeeeb7653d35c299",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "computing precision with alignments, completed variants ::   0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbf1ca6822e84c3b9d2520602f007e51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "replaying log with TBR, completed traces ::   0%|          | 0/54 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_11976\\2035488507.py:10: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_stratified = df.groupby('concept:name').apply(lambda x: x.sample(5)).reset_index(drop=True)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e66c6eda42074d618327b38991c80ce6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "aligning log, completed variants ::   0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccd16db79ad44c5db4c430c3aed77542",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "computing precision with alignments, completed variants ::   0%|          | 0/87 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5b404efc6334aee9c2a5f9afc710a0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "replaying log with TBR, completed traces ::   0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b95794ea2c8c44a3a0a332ba3405c85f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "aligning log, completed variants ::   0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cd351c7a5f841a5b9d14721533d1297",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "computing precision with alignments, completed variants ::   0%|          | 0/87 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51cf8c3f29414dcc931886a704053506",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "replaying log with TBR, completed traces ::   0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7742b8912cdc46559a54c5a6db04f2f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "aligning log, completed variants ::   0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3388f052b377481298061e47ee258bfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "computing precision with alignments, completed variants ::   0%|          | 0/87 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ea83b0619334c4db494e9151c9a21a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "replaying log with TBR, completed traces ::   0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load dataset\n",
    "\n",
    "input_file = os.path.join('data', 'raw', 'tm001.txt')\n",
    "\n",
    "dataset_approaches = [\"daily\", \"session\"]\n",
    "\n",
    "for ds_approach in dataset_approaches:\n",
    "\n",
    "    df = prepare_dataset(input_file, approach=ds_approach)\n",
    "    df_stratified = df.groupby('concept:name').apply(lambda x: x.sample(5)).reset_index(drop=True)\n",
    "\n",
    "    # Convert to event log\n",
    "    log = pm4py.convert_to_event_log(df_stratified)\n",
    "\n",
    "    # Apply process mining\n",
    "    models = apply_process_mining(log)\n",
    "\n",
    "    # Calculate metrics\n",
    "    metrics = calculate_metrics(log, models)\n",
    "\n",
    "    # Plot comparisons\n",
    "    plot_metrics_comparison(metrics, ds_approach, figures_folder)\n",
    "\n",
    "    # Visualize Petri nets\n",
    "    visualize_petri_nets(models, ds_approach, figures_folder)\n",
    "\n",
    "    # Analyze user habits\n",
    "    user_habits_path = os.path.join('data', 'processed')\n",
    "    habits = analyze_user_habits(log, ds_approach, user_habits_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
